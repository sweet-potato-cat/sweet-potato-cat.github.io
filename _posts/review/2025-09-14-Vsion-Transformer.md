---
layout: post
title: "Vision-Transformer"
subtitle: "an image is worth 16x16 words transformers for image recognition at scale"
category: review
tags: ai
image:
  path: /assets/img/PaperReview/vit_architecture.jpg
---

NLP 테스크에서 주로 쓰이던 Transformer 아키텍처가 Vision 분야에 쓰이는 것이 흥미로워서 이 논문을 선택해 리뷰하게 되었습니다.

<!--more-->

* this unordered seed list will be replaced by the toc
{:toc}

## 개요
## 선행연구
* Transformer architecture (Vaswani et al., 2017)
* Self-Atterntion mechanism
## 모델
![Model Architecture](/assets/img/PaperReview/vit_architecture.jpg)
## 가설
CNN 고유의 inductive bias 없이도, 대규모 데이터로 사전학습한다면 CNN 의존이 없는 Transformer만으로도 이미지 인식에서 SOTA 성능을 달성할 수 있다
## 실험 과정 및 결과
## 나의 생각 및 궁금증
## 결론

